version: '3'
services:
  elasticsearch:
    image: zhengdai/es_ik:7.10.1
    container_name: elasticsearch
    ports:
    - "9200:9200"
    - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xmx1G -Xms1G"
      ELASTIC_PASSWORD: changeme
    healthcheck:
      test: [ "CMD-SHELL", "curl --user elastic:changeme --silent --fail localhost:9200/_cluster/health || exit 1" ]
      interval: 30s
      timeout: 30s
      retries: 3
    volumes:
    - ./config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    - ./datas/es/:/usr/share/elasticsearch/data
    networks:
    - elasticsearch

  kibana:
    image: kibana:7.10.1
    container_name: kibana
    ports:
    - "8888:5601"
    volumes:
    - ./config/kibana.yml:/usr/share/kibana/config/kibana.yml
    networks:
    - elasticsearch
    depends_on:
    - elasticsearch

  api: # Node.js App
    container_name: api
    build: .
    ports:
    - "3000:3000" # Expose API port
#    - "9229:9229" # Expose Node process debug port (disable in production)
    environment: # Set ENV vars
    - NODE_ENV=local
    - ES_HOST=elasticsearch
    - PORT=3000
    volumes: # Attach local book data directory
    - ./books:/usr/src/app/books
    networks:
    - elasticsearch

  frontend: # Nginx Server For Frontend App
    container_name: frontend
    image: nginx
    volumes: # Serve local "public" dir
    - ./public:/usr/share/nginx/html
    ports:
    - "8889:80" # Forward site to localhost:8080
    networks:
    - elasticsearch

  fscrawler: # 文档自动存es
    container_name: fscrawler
    image: toto1310/fscrawler:2.7-SNAPSHOT
    volumes:
    - ./fscrawler:/root/.fscrawler #配置文件夹
    - ./books:/usr/share/fscrawler/data #文档目录
    networks:
    - elasticsearch
    depends_on:
    - elasticsearch
    restart: unless-stopped
    command: FS_JAVA_OPTS="-DLOG_DIR=/usr/share/fscrawler/logs -DLOG_LEVEL=trace -DDOC_LEVEL=debug" fscrawler myjob

networks:
  elasticsearch:
    driver: bridge
